{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93ab7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import time\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9061273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def build_projection_matrix(w, h, fov):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "    \"\"\"Project 3D point (world) to 2D pixel (image).\"\"\"\n",
    "    point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "    point_camera = np.dot(w2c, point)\n",
    "    point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "    point_img = np.dot(K, point_camera)\n",
    "    if point_img[2] != 0:\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "    return point_img[0:2]\n",
    "\n",
    "# Edges of the 3D bounding box\n",
    "BB_EDGES = [\n",
    "    [0,1], [1,3], [3,2], [2,0],\n",
    "    [0,4], [4,5], [5,1], [5,7],\n",
    "    [7,6], [6,4], [6,2], [7,3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c46c0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Connect to CARLA\n",
    "# ----------------------------\n",
    "\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "client.set_timeout(10.0)\n",
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3047a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Spawn ego vehicle\n",
    "# ----------------------------\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = blueprint_library.filter('*mini*')[0]\n",
    "spawn_point = world.get_map().get_spawn_points()[0]\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc15c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Attach RGB camera\n",
    "# ----------------------------\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '1280')\n",
    "camera_bp.set_attribute('image_size_y', '720')\n",
    "camera_bp.set_attribute('fov', '90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7226557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_init_trans = carla.Transform(carla.Location(x=-5, z=2))  # behind and above car\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc83595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image holder\n",
    "image_w = int(camera_bp.get_attribute(\"image_size_x\").as_int())\n",
    "image_h = int(camera_bp.get_attribute(\"image_size_y\").as_int())\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3dab9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_callback(image, data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image, camera_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f2eefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Prepare projection\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# Prepare projection\n",
    "# ----------------------------\n",
    "K = build_projection_matrix(image_w, image_h, float(camera_bp.get_attribute('fov').as_float()))\n",
    "\n",
    "# Collect bounding boxes of various object types\n",
    "bbs = {\n",
    "    \"TrafficLight\": (world.get_level_bbs(carla.CityObjectLabel.TrafficLight), (0, 0, 255)),   # red\n",
    "    \"Vehicle\":      (world.get_level_bbs(carla.CityObjectLabel.Vehicle), (0, 255, 0)),       # green\n",
    "    \"Pedestrian\":   (world.get_level_bbs(carla.CityObjectLabel.Pedestrians), (255, 0, 0)),   # blue\n",
    "    \"TrafficSign\":  (world.get_level_bbs(carla.CityObjectLabel.TrafficSigns), (0, 255, 255)) # yellow\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# OpenCV window\n",
    "# ----------------------------\n",
    "cv2.namedWindow(\"RGB Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        world.tick()\n",
    "        vehicle.set_autopilot(True)\n",
    "\n",
    "        img = camera_data['image'].copy()\n",
    "\n",
    "        # Project traffic light bounding boxes\n",
    "        vehicle_transform = vehicle.get_transform()\n",
    "        w2c = np.array(camera.get_transform().get_inverse_matrix())\n",
    "        for bb in traffic_light_bbs:\n",
    "            if bb.location.distance(vehicle_transform.location) < 50:\n",
    "                forward_vec = vehicle_transform.get_forward_vector()\n",
    "                ray = bb.location - vehicle_transform.location\n",
    "                if forward_vec.dot(ray) > 0:  # only draw in front\n",
    "                    verts = [v for v in bb.get_world_vertices(carla.Transform())]\n",
    "                    for edge in BB_EDGES:\n",
    "                        p1 = get_image_point(verts[edge[0]], K, w2c)\n",
    "                        p2 = get_image_point(verts[edge[1]], K, w2c)\n",
    "                        if (0 <= p1[0] < image_w and 0 <= p1[1] < image_h and\n",
    "                            0 <= p2[0] < image_w and 0 <= p2[1] < image_h):\n",
    "                            cv2.line(img, (int(p1[0]), int(p1[1])),\n",
    "                                          (int(p2[0]), int(p2[1])),\n",
    "                                          (0, 0, 255), 1)  # red box\n",
    "\n",
    "        cv2.imshow(\"RGB Camera\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.stop()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef1aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
